{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#import Keras library\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM, Input, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.metrics import categorical_accuracy\n",
    "\n",
    "# spacy is used to work on text\n",
    "import spacy\n",
    "\n",
    "#import other libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import codecs\n",
    "import collections\n",
    "import string\n",
    "import re\n",
    "from six.moves import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('wiki_movie_plots_deduped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A bartender is working at a saloon, serving drinks to customers. After he fills a stereotypically Irish man's bucket with beer, Carrie Nation and her followers burst inside. They assault the Irish man, pulling his hat over his eyes and then dumping the beer over his head. The group then begin wrecking the bar, smashing the fixtures, mirrors, and breaking the cash register. The bartender then sprays seltzer water in Nation's face before a group of policemen appear and order everybody to leave.[1]\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Plot[0]#.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wordlist(doc):\n",
    "    wl = []\n",
    "    for word in re.split(' |\\r\\n',doc):\n",
    "        word = word.lower()\n",
    "        punc = string.punctuation.replace(\"'\", \"\")\n",
    "        if '[' in word and ']' in word:\n",
    "            start = word.index('[')\n",
    "            end = word.index(']')\n",
    "            word = word[:start] + word[end+1:]\n",
    "        for i in punc:\n",
    "            word = word.replace(i, \"\")\n",
    "        wl.append(word.lower())\n",
    "    return wl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34886,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Plot'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.Plot[1].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0.08117413520812988 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "wordlist = []\n",
    "\n",
    "for i in df['Plot'][:100]:\n",
    "    wl = create_wordlist(i)\n",
    "    wordlist = wordlist + wl\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15339"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12993831"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size:  3600\n"
     ]
    }
   ],
   "source": [
    "# count the number of words\n",
    "word_counts = collections.Counter(wordlist)\n",
    "\n",
    "# Mapping from index to word : that's the vocabulary\n",
    "vocabulary_inv = [x[0] for x in word_counts.most_common()]\n",
    "vocabulary_inv = list(sorted(vocabulary_inv))\n",
    "\n",
    "# Mapping from word to index\n",
    "vocab = {x: i for i, x in enumerate(vocabulary_inv)}\n",
    "words = [x[0] for x in word_counts.most_common()]\n",
    "\n",
    "#size of the vocabulary\n",
    "vocab_size = len(words)\n",
    "print(\"vocab size: \", vocab_size)\n",
    "\n",
    "# #save the words and vocabulary\n",
    "# with open('word_dict.txt', 'wb') as f:\n",
    "#     cPickle.dump((words, vocab, vocabulary_inv), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_size = 256 # size of RNN\n",
    "seq_length = 10 # sequence length\n",
    "learning_rate = 0.001 #learning rate\n",
    "sequences_step = 1 #step to create sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('word_dict.txt', 'rb') as f:\n",
    "#     w = cPickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 15329\n"
     ]
    }
   ],
   "source": [
    "#create sequences\n",
    "sequences = []\n",
    "next_words = []\n",
    "for i in range(0, len(wordlist) - seq_length, sequences_step):\n",
    "    sequences.append(wordlist[i: i + seq_length])\n",
    "    next_words.append(wordlist[i + seq_length])\n",
    "\n",
    "print('nb sequences:', len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5115978419780731"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "15259 * 10 * 3600 / 1024.0**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(sequences), seq_length, vocab_size), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), vocab_size), dtype=np.bool)\n",
    "for i, sentence in enumerate(sequences):\n",
    "    for t, word in enumerate(sentence):\n",
    "        X[i, t, vocab[word]] = 1\n",
    "    y[i, vocab[next_words[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bidirectional_lstm_model(seq_length, vocab_size):\n",
    "    print('Build LSTM model.')\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(rnn_size, activation=\"relu\"),input_shape=(seq_length, vocab_size)))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(vocab_size))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    callbacks=[EarlyStopping(patience=2, monitor='val_loss')]\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[categorical_accuracy])\n",
    "    print(\"model built!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build LSTM model.\n",
      "WARNING:tensorflow:From /home/hsiaoyuchiang/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hsiaoyuchiang/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model built!\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 512)               7899136   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3600)              1846800   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3600)              0         \n",
      "=================================================================\n",
      "Total params: 9,745,936\n",
      "Trainable params: 9,745,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_size = 256 # size of RNN\n",
    "seq_length = 10 # sequence length\n",
    "learning_rate = 0.001 #learning rate\n",
    "\n",
    "md = bidirectional_lstm_model(seq_length, vocab_size)\n",
    "md.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hsiaoyuchiang/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hsiaoyuchiang/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13796 samples, validate on 1533 samples\n",
      "Epoch 1/50\n",
      "13796/13796 [==============================] - 228s 17ms/step - loss: 6.7177 - categorical_accuracy: 0.0840 - val_loss: 6.4987 - val_categorical_accuracy: 0.0855\n",
      "Epoch 2/50\n",
      "13796/13796 [==============================] - 226s 16ms/step - loss: 6.2706 - categorical_accuracy: 0.0850 - val_loss: 6.5930 - val_categorical_accuracy: 0.0855\n",
      "Epoch 3/50\n",
      "13796/13796 [==============================] - 226s 16ms/step - loss: 6.0963 - categorical_accuracy: 0.0853 - val_loss: 6.6868 - val_categorical_accuracy: 0.0861\n",
      "Epoch 4/50\n",
      "13796/13796 [==============================] - 223s 16ms/step - loss: 5.9204 - categorical_accuracy: 0.0857 - val_loss: 6.8409 - val_categorical_accuracy: 0.0887\n",
      "Epoch 5/50\n",
      "13796/13796 [==============================] - 225s 16ms/step - loss: 5.7450 - categorical_accuracy: 0.0898 - val_loss: 6.9979 - val_categorical_accuracy: 0.0985\n",
      "Epoch 6/50\n",
      "13796/13796 [==============================] - 234s 17ms/step - loss: 5.5546 - categorical_accuracy: 0.0987 - val_loss: 7.1725 - val_categorical_accuracy: 0.0978\n",
      "Epoch 7/50\n",
      "13796/13796 [==============================] - 236s 17ms/step - loss: 5.3202 - categorical_accuracy: 0.1221 - val_loss: 7.3788 - val_categorical_accuracy: 0.1063\n",
      "Epoch 8/50\n",
      "13796/13796 [==============================] - 231s 17ms/step - loss: 5.0538 - categorical_accuracy: 0.1490 - val_loss: 7.9345 - val_categorical_accuracy: 0.0998\n",
      "Epoch 9/50\n",
      "13796/13796 [==============================] - 230s 17ms/step - loss: 4.7676 - categorical_accuracy: 0.1799 - val_loss: 8.0804 - val_categorical_accuracy: 0.0926\n",
      "Epoch 10/50\n",
      "13796/13796 [==============================] - 234s 17ms/step - loss: 4.4813 - categorical_accuracy: 0.2138 - val_loss: 8.3578 - val_categorical_accuracy: 0.0965\n",
      "Epoch 11/50\n",
      "13796/13796 [==============================] - 237s 17ms/step - loss: 4.1815 - categorical_accuracy: 0.2448 - val_loss: 8.7430 - val_categorical_accuracy: 0.0861\n",
      "Epoch 12/50\n",
      "13796/13796 [==============================] - 235s 17ms/step - loss: 3.8473 - categorical_accuracy: 0.2836 - val_loss: 8.9031 - val_categorical_accuracy: 0.0763\n",
      "Epoch 13/50\n",
      "13796/13796 [==============================] - 236s 17ms/step - loss: 3.4965 - categorical_accuracy: 0.3282 - val_loss: 9.3311 - val_categorical_accuracy: 0.0887\n",
      "Epoch 14/50\n",
      "13796/13796 [==============================] - 232s 17ms/step - loss: 3.1131 - categorical_accuracy: 0.3772 - val_loss: 9.7666 - val_categorical_accuracy: 0.0815\n",
      "Epoch 15/50\n",
      "13796/13796 [==============================] - 233s 17ms/step - loss: 2.7272 - categorical_accuracy: 0.4396 - val_loss: 10.7035 - val_categorical_accuracy: 0.0691\n",
      "Epoch 16/50\n",
      "13796/13796 [==============================] - 232s 17ms/step - loss: 2.3534 - categorical_accuracy: 0.4972 - val_loss: 10.7494 - val_categorical_accuracy: 0.0705\n",
      "Epoch 17/50\n",
      "13796/13796 [==============================] - 236s 17ms/step - loss: 1.9770 - categorical_accuracy: 0.5668 - val_loss: 10.5757 - val_categorical_accuracy: 0.0633\n",
      "Epoch 18/50\n",
      "13796/13796 [==============================] - 236s 17ms/step - loss: 1.6491 - categorical_accuracy: 0.6299 - val_loss: 11.4380 - val_categorical_accuracy: 0.0665\n",
      "Epoch 19/50\n",
      "13796/13796 [==============================] - 238s 17ms/step - loss: 1.3796 - categorical_accuracy: 0.6888 - val_loss: 12.0433 - val_categorical_accuracy: 0.0607\n",
      "Epoch 20/50\n",
      "13796/13796 [==============================] - 236s 17ms/step - loss: 1.1392 - categorical_accuracy: 0.7324 - val_loss: 12.3430 - val_categorical_accuracy: 0.0574\n",
      "Epoch 21/50\n",
      "13796/13796 [==============================] - 235s 17ms/step - loss: 0.9755 - categorical_accuracy: 0.7745 - val_loss: 12.2877 - val_categorical_accuracy: 0.0639\n",
      "Epoch 22/50\n",
      "13796/13796 [==============================] - 239s 17ms/step - loss: 0.8209 - categorical_accuracy: 0.8040 - val_loss: 12.2321 - val_categorical_accuracy: 0.0594\n",
      "Epoch 23/50\n",
      "13796/13796 [==============================] - 238s 17ms/step - loss: 0.6969 - categorical_accuracy: 0.8321 - val_loss: 13.9751 - val_categorical_accuracy: 0.0528\n",
      "Epoch 24/50\n",
      "13796/13796 [==============================] - 244s 18ms/step - loss: 0.5860 - categorical_accuracy: 0.8542 - val_loss: 14.3655 - val_categorical_accuracy: 0.0607\n",
      "Epoch 25/50\n",
      "13796/13796 [==============================] - 253s 18ms/step - loss: 0.5328 - categorical_accuracy: 0.8686 - val_loss: 12.9788 - val_categorical_accuracy: 0.0574\n",
      "Epoch 26/50\n",
      "13796/13796 [==============================] - 241s 17ms/step - loss: 0.4720 - categorical_accuracy: 0.8858 - val_loss: 13.3132 - val_categorical_accuracy: 0.0554\n",
      "Epoch 27/50\n",
      "13796/13796 [==============================] - 237s 17ms/step - loss: 0.4006 - categorical_accuracy: 0.8987 - val_loss: 13.1423 - val_categorical_accuracy: 0.0561\n",
      "Epoch 28/50\n",
      "13796/13796 [==============================] - 243s 18ms/step - loss: 0.4130 - categorical_accuracy: 0.8995 - val_loss: 13.1165 - val_categorical_accuracy: 0.0502\n",
      "Epoch 29/50\n",
      "13796/13796 [==============================] - 237s 17ms/step - loss: 0.3576 - categorical_accuracy: 0.9110 - val_loss: 13.8446 - val_categorical_accuracy: 0.0607\n",
      "Epoch 30/50\n",
      "13796/13796 [==============================] - 235s 17ms/step - loss: 0.3083 - categorical_accuracy: 0.9251 - val_loss: 13.5255 - val_categorical_accuracy: 0.0607\n",
      "Epoch 31/50\n",
      "13796/13796 [==============================] - 237s 17ms/step - loss: 0.2917 - categorical_accuracy: 0.9295 - val_loss: 13.6883 - val_categorical_accuracy: 0.0613\n",
      "Epoch 32/50\n",
      "13796/13796 [==============================] - 240s 17ms/step - loss: 0.2769 - categorical_accuracy: 0.9336 - val_loss: 13.5716 - val_categorical_accuracy: 0.0535\n",
      "Epoch 33/50\n",
      "13796/13796 [==============================] - 243s 18ms/step - loss: 0.2420 - categorical_accuracy: 0.9404 - val_loss: 14.5910 - val_categorical_accuracy: 0.0613\n",
      "Epoch 34/50\n",
      "13796/13796 [==============================] - 240s 17ms/step - loss: 0.2301 - categorical_accuracy: 0.9430 - val_loss: 12.7646 - val_categorical_accuracy: 0.0600\n",
      "Epoch 35/50\n",
      "13796/13796 [==============================] - 239s 17ms/step - loss: 0.2279 - categorical_accuracy: 0.9465 - val_loss: 12.0525 - val_categorical_accuracy: 0.0515\n",
      "Epoch 36/50\n",
      "13796/13796 [==============================] - 239s 17ms/step - loss: 0.2076 - categorical_accuracy: 0.9487 - val_loss: 13.9346 - val_categorical_accuracy: 0.0535\n",
      "Epoch 37/50\n",
      "13796/13796 [==============================] - 242s 18ms/step - loss: 0.1940 - categorical_accuracy: 0.9534 - val_loss: 12.4338 - val_categorical_accuracy: 0.0483\n",
      "Epoch 38/50\n",
      "13796/13796 [==============================] - 244s 18ms/step - loss: 0.1750 - categorical_accuracy: 0.9567 - val_loss: 13.8164 - val_categorical_accuracy: 0.0587\n",
      "Epoch 39/50\n",
      "13796/13796 [==============================] - 248s 18ms/step - loss: 0.1639 - categorical_accuracy: 0.9601 - val_loss: 14.3211 - val_categorical_accuracy: 0.0554\n",
      "Epoch 40/50\n",
      "13796/13796 [==============================] - 249s 18ms/step - loss: 0.1680 - categorical_accuracy: 0.9585 - val_loss: 13.3766 - val_categorical_accuracy: 0.0587\n",
      "Epoch 41/50\n",
      "13796/13796 [==============================] - 248s 18ms/step - loss: 0.1521 - categorical_accuracy: 0.9629 - val_loss: 13.5138 - val_categorical_accuracy: 0.0515\n",
      "Epoch 42/50\n",
      "13796/13796 [==============================] - 252s 18ms/step - loss: 0.1557 - categorical_accuracy: 0.9625 - val_loss: 13.0764 - val_categorical_accuracy: 0.0444\n",
      "Epoch 43/50\n",
      "13796/13796 [==============================] - 252s 18ms/step - loss: 0.1424 - categorical_accuracy: 0.9656 - val_loss: 13.5284 - val_categorical_accuracy: 0.0548\n",
      "Epoch 44/50\n",
      "13796/13796 [==============================] - 260s 19ms/step - loss: 0.1488 - categorical_accuracy: 0.9652 - val_loss: 13.3106 - val_categorical_accuracy: 0.0568\n",
      "Epoch 45/50\n",
      "13796/13796 [==============================] - 256s 19ms/step - loss: 0.1057 - categorical_accuracy: 0.9733 - val_loss: 15.1600 - val_categorical_accuracy: 0.0626\n",
      "Epoch 46/50\n",
      "13796/13796 [==============================] - 254s 18ms/step - loss: 0.1202 - categorical_accuracy: 0.9699 - val_loss: 13.1213 - val_categorical_accuracy: 0.0535\n",
      "Epoch 47/50\n",
      "13796/13796 [==============================] - 232s 17ms/step - loss: 0.1269 - categorical_accuracy: 0.9697 - val_loss: 14.0855 - val_categorical_accuracy: 0.0587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      "13796/13796 [==============================] - 238s 17ms/step - loss: 0.1025 - categorical_accuracy: 0.9749 - val_loss: 13.7480 - val_categorical_accuracy: 0.0515\n",
      "Epoch 49/50\n",
      "13796/13796 [==============================] - 237s 17ms/step - loss: 0.1155 - categorical_accuracy: 0.9728 - val_loss: 13.4590 - val_categorical_accuracy: 0.0417\n",
      "Epoch 50/50\n",
      "13796/13796 [==============================] - 241s 17ms/step - loss: 0.1269 - categorical_accuracy: 0.9698 - val_loss: 13.3474 - val_categorical_accuracy: 0.0607\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-bed11e25e290>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'my_model_generate_sentences.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'save_dir' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 32 # minibatch size\n",
    "num_epochs = 50 # number of epochs\n",
    "\n",
    "# callbacks=[EarlyStopping(patience=4, monitor='val_loss'),\n",
    "#            ModelCheckpoint(filepath=save_dir + \"/\" + 'my_model_gen_sentences.{epoch:02d}-{val_loss:.2f}.hdf5',\\\n",
    "#                            monitor='val_loss', verbose=0, mode='auto', period=2)]\n",
    "#fit the model\n",
    "history = md.fit(X, y,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True,\n",
    "                 epochs=num_epochs,\n",
    "#                  callbacks=callbacks,\n",
    "                 validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "md.save('my_model_generate_sentences.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vocabulary...\n",
      "loading model...\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "#load vocabulary\n",
    "print(\"loading vocabulary...\")\n",
    "# vocab_file = os.path.join(save_dir, \"words_vocab.pkl\")\n",
    "\n",
    " \n",
    "with open('word_dict_short.txt', 'wb') as f:\n",
    "    cPickle.dump((words, vocab, vocabulary_inv), f)\n",
    "\n",
    "with open('word_dict_short.txt', 'rb') as f:\n",
    "    words, vocab, vocabulary_inv = cPickle.load(f)\n",
    "\n",
    "vocab_size = len(words)\n",
    "\n",
    "from keras.models import load_model\n",
    "# load the model\n",
    "print(\"loading model...\")\n",
    "model = load_model('my_model_generate_sentences.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " \"'dick'\": 1,\n",
       " \"'girl'\": 2,\n",
       " '1422–1461': 3,\n",
       " '1455–1487': 4,\n",
       " '1470–1471': 5,\n",
       " '15': 6,\n",
       " '1900': 7,\n",
       " '1909': 8,\n",
       " '1910': 9,\n",
       " '1911': 10,\n",
       " '1913': 11,\n",
       " '1914': 12,\n",
       " '1915': 13,\n",
       " '20000': 14,\n",
       " '3': 15,\n",
       " '3–5': 16,\n",
       " '4': 17,\n",
       " \"45's\": 18,\n",
       " '4–6': 19,\n",
       " '5': 20,\n",
       " '6': 21,\n",
       " '61': 22,\n",
       " '7': 23,\n",
       " '8': 24,\n",
       " 'a': 25,\n",
       " 'abandon': 26,\n",
       " 'abandoning': 27,\n",
       " 'abandons': 28,\n",
       " 'abduct': 29,\n",
       " 'abducted': 30,\n",
       " 'abduction': 31,\n",
       " 'able': 32,\n",
       " 'aboard': 33,\n",
       " 'about': 34,\n",
       " 'absconded': 35,\n",
       " 'absence': 36,\n",
       " 'absent': 37,\n",
       " 'abuse': 38,\n",
       " 'abusive': 39,\n",
       " 'accept': 40,\n",
       " 'accepts': 41,\n",
       " 'accident': 42,\n",
       " 'accidentally': 43,\n",
       " 'accompanied': 44,\n",
       " 'accompanying': 45,\n",
       " 'accosts': 46,\n",
       " 'accurate': 47,\n",
       " 'accused': 48,\n",
       " 'accuses': 49,\n",
       " 'acknowledged': 50,\n",
       " 'acquaintance': 51,\n",
       " 'acquainted': 52,\n",
       " 'across': 53,\n",
       " 'act': 54,\n",
       " 'action': 55,\n",
       " 'actions': 56,\n",
       " 'actor': 57,\n",
       " 'actors': 58,\n",
       " \"actors'\": 59,\n",
       " \"actress'\": 60,\n",
       " 'ad': 61,\n",
       " 'adair': 62,\n",
       " 'adaptation': 63,\n",
       " 'addicted': 64,\n",
       " 'adieu—after': 65,\n",
       " 'adjacent': 66,\n",
       " 'administering': 67,\n",
       " 'admirer': 68,\n",
       " 'admirers': 69,\n",
       " 'adolescent': 70,\n",
       " 'adult': 71,\n",
       " 'adultery': 72,\n",
       " 'advantage': 73,\n",
       " 'adventure': 74,\n",
       " 'adventures': 75,\n",
       " 'advice': 76,\n",
       " 'affair': 77,\n",
       " 'affairs': 78,\n",
       " 'afoul': 79,\n",
       " 'afraid': 80,\n",
       " 'after': 81,\n",
       " 'afternoon': 82,\n",
       " 'afterward': 83,\n",
       " 'afterwards': 84,\n",
       " 'again': 85,\n",
       " 'against': 86,\n",
       " 'age': 87,\n",
       " 'aged': 88,\n",
       " 'agent': 89,\n",
       " 'aghast': 90,\n",
       " 'aging': 91,\n",
       " 'agree': 92,\n",
       " 'agreed': 93,\n",
       " 'agrees': 94,\n",
       " 'aid': 95,\n",
       " 'aided': 96,\n",
       " 'aims': 97,\n",
       " 'air': 98,\n",
       " 'aitken': 99,\n",
       " 'alarm': 100,\n",
       " 'albeit': 101,\n",
       " 'alden': 102,\n",
       " 'alerting': 103,\n",
       " 'alessandro': 104,\n",
       " \"alessandro's\": 105,\n",
       " 'ali': 106,\n",
       " 'alias': 107,\n",
       " 'alibi': 108,\n",
       " 'alice': 109,\n",
       " 'alicia': 110,\n",
       " 'alive': 111,\n",
       " 'all': 112,\n",
       " 'allowed': 113,\n",
       " 'allowing': 114,\n",
       " 'almost': 115,\n",
       " 'aloft': 116,\n",
       " 'alone': 117,\n",
       " 'along': 118,\n",
       " 'already': 119,\n",
       " 'also': 120,\n",
       " 'altar': 121,\n",
       " 'alter': 122,\n",
       " 'altercation': 123,\n",
       " 'although': 124,\n",
       " 'always': 125,\n",
       " 'ambassador': 126,\n",
       " 'ambitious': 127,\n",
       " 'ambrose': 128,\n",
       " \"ambrose's\": 129,\n",
       " 'ambulance': 130,\n",
       " 'amends': 131,\n",
       " 'america': 132,\n",
       " 'american': 133,\n",
       " 'among': 134,\n",
       " 'amount': 135,\n",
       " 'amounts': 136,\n",
       " 'amused': 137,\n",
       " 'an': 138,\n",
       " 'anaesthesic': 139,\n",
       " 'and': 140,\n",
       " 'andrews': 141,\n",
       " \"andrews'\": 142,\n",
       " 'anger': 143,\n",
       " 'angrily': 144,\n",
       " 'angry': 145,\n",
       " 'animal': 146,\n",
       " 'animated': 147,\n",
       " 'announce': 148,\n",
       " 'announced': 149,\n",
       " 'announces': 150,\n",
       " 'anonymous': 151,\n",
       " 'another': 152,\n",
       " 'answer': 153,\n",
       " 'answers': 154,\n",
       " 'antidote': 155,\n",
       " 'any': 156,\n",
       " 'apartment': 157,\n",
       " 'apologetic': 158,\n",
       " 'apology': 159,\n",
       " 'apparently': 160,\n",
       " 'appear': 161,\n",
       " 'appearance': 162,\n",
       " 'appeared': 163,\n",
       " 'appearing': 164,\n",
       " 'appears': 165,\n",
       " 'appleyard': 166,\n",
       " 'approaches': 167,\n",
       " 'arab': 168,\n",
       " 'arabian': 169,\n",
       " 'arblaster': 170,\n",
       " 'arbuckle': 171,\n",
       " 'are': 172,\n",
       " 'aresenals': 173,\n",
       " 'argentina': 174,\n",
       " 'argues': 175,\n",
       " 'arguing': 176,\n",
       " 'arises': 177,\n",
       " 'arm': 178,\n",
       " 'arminarm': 179,\n",
       " 'arms': 180,\n",
       " 'army': 181,\n",
       " 'around': 182,\n",
       " 'arranged': 183,\n",
       " 'arrest': 184,\n",
       " 'arrested': 185,\n",
       " 'arresting': 186,\n",
       " 'arrive': 187,\n",
       " 'arrived': 188,\n",
       " 'arrives': 189,\n",
       " 'arriving': 190,\n",
       " 'arrow': 191,\n",
       " 'arrows': 192,\n",
       " 'art': 193,\n",
       " 'arthur': 194,\n",
       " 'artistic': 195,\n",
       " 'as': 196,\n",
       " 'ascends': 197,\n",
       " 'asides': 198,\n",
       " 'asks': 199,\n",
       " 'asleep': 200,\n",
       " 'aspire': 201,\n",
       " 'assailants': 202,\n",
       " 'assassin': 203,\n",
       " 'assassination': 204,\n",
       " 'assault': 205,\n",
       " 'assist': 206,\n",
       " 'assistant': 207,\n",
       " 'assists': 208,\n",
       " 'association': 209,\n",
       " 'at': 210,\n",
       " 'athletes': 211,\n",
       " 'atlantic': 212,\n",
       " 'atop': 213,\n",
       " 'attack': 214,\n",
       " 'attacked': 215,\n",
       " 'attacks': 216,\n",
       " 'attempt': 217,\n",
       " 'attempting': 218,\n",
       " 'attempts': 219,\n",
       " 'attendance': 220,\n",
       " 'attention': 221,\n",
       " 'attentions': 222,\n",
       " 'attire': 223,\n",
       " 'attract': 224,\n",
       " 'attracted': 225,\n",
       " 'attractive': 226,\n",
       " 'audience': 227,\n",
       " 'audition': 228,\n",
       " 'author': 229,\n",
       " 'auto': 230,\n",
       " 'automobile': 231,\n",
       " 'avenge': 232,\n",
       " 'avoid': 233,\n",
       " 'await': 234,\n",
       " 'awake': 235,\n",
       " 'awakens': 236,\n",
       " 'aware': 237,\n",
       " 'away': 238,\n",
       " 'axe': 239,\n",
       " 'b': 240,\n",
       " 'baba': 241,\n",
       " 'baby': 242,\n",
       " 'back': 243,\n",
       " 'backdrop': 244,\n",
       " 'backs': 245,\n",
       " 'backstage': 246,\n",
       " 'backwards': 247,\n",
       " 'badly': 248,\n",
       " 'baggot': 249,\n",
       " 'baggy': 250,\n",
       " 'bakery': 251,\n",
       " 'balanced': 252,\n",
       " 'balcony': 253,\n",
       " 'ball': 254,\n",
       " 'balloon': 255,\n",
       " 'ballpark': 256,\n",
       " 'band': 257,\n",
       " 'bandage': 258,\n",
       " 'bandit': 259,\n",
       " 'bandits': 260,\n",
       " 'bandits\\u200d—\\u200cnow': 261,\n",
       " 'banished': 262,\n",
       " 'bank': 263,\n",
       " 'banker': 264,\n",
       " 'banks': 265,\n",
       " 'bar': 266,\n",
       " 'barely': 267,\n",
       " 'bargepole': 268,\n",
       " 'barn': 269,\n",
       " 'barney': 270,\n",
       " 'barrage': 271,\n",
       " 'barrel': 272,\n",
       " 'barriscale': 273,\n",
       " 'bars': 274,\n",
       " 'bartender': 275,\n",
       " 'base': 276,\n",
       " 'baseball': 277,\n",
       " 'bases': 278,\n",
       " 'basket': 279,\n",
       " 'basketball': 280,\n",
       " 'battery': 281,\n",
       " 'battle': 282,\n",
       " 'battlefield': 283,\n",
       " 'battlements': 284,\n",
       " 'battling': 285,\n",
       " 'be': 286,\n",
       " 'beach': 287,\n",
       " 'bean': 288,\n",
       " 'beans': 289,\n",
       " 'beanstalk': 290,\n",
       " 'bearing': 291,\n",
       " 'beast': 292,\n",
       " 'beat': 293,\n",
       " 'beaten': 294,\n",
       " 'beau': 295,\n",
       " 'beaus': 296,\n",
       " 'beautiful': 297,\n",
       " 'because': 298,\n",
       " 'become': 299,\n",
       " 'becomes': 300,\n",
       " 'becoming': 301,\n",
       " 'bed': 302,\n",
       " 'bedclothes': 303,\n",
       " 'bedraggled': 304,\n",
       " 'bedroom': 305,\n",
       " 'been': 306,\n",
       " 'beer': 307,\n",
       " 'before': 308,\n",
       " 'befriends': 309,\n",
       " 'begging': 310,\n",
       " 'begin': 311,\n",
       " 'beginning': 312,\n",
       " 'begins': 313,\n",
       " 'begs': 314,\n",
       " 'behead': 315,\n",
       " 'behind': 316,\n",
       " 'beig': 317,\n",
       " 'being': 318,\n",
       " 'believe': 319,\n",
       " 'believes': 320,\n",
       " 'believing': 321,\n",
       " 'bell': 322,\n",
       " 'belongings': 323,\n",
       " 'beloved': 324,\n",
       " 'below': 325,\n",
       " 'belts': 326,\n",
       " 'bench': 327,\n",
       " 'bend': 328,\n",
       " 'bending': 329,\n",
       " 'bennet': 330,\n",
       " 'bentley': 331,\n",
       " 'berlin': 332,\n",
       " 'beside': 333,\n",
       " 'besotted': 334,\n",
       " 'bet': 335,\n",
       " 'better': 336,\n",
       " 'between': 337,\n",
       " 'beyond': 338,\n",
       " 'biblett': 339,\n",
       " 'bicycle': 340,\n",
       " 'bids': 341,\n",
       " 'big': 342,\n",
       " 'bigger': 343,\n",
       " 'biggest': 344,\n",
       " 'bike': 345,\n",
       " 'bill': 346,\n",
       " 'billed': 347,\n",
       " 'bindle': 348,\n",
       " 'biograph': 349,\n",
       " 'birch': 350,\n",
       " 'bird': 351,\n",
       " 'bisexual': 352,\n",
       " 'black': 353,\n",
       " 'blacksmith': 354,\n",
       " 'blamed': 355,\n",
       " 'blanche': 356,\n",
       " 'bland': 357,\n",
       " 'blesses': 358,\n",
       " 'blindfolded': 359,\n",
       " 'blocked': 360,\n",
       " 'blonde': 361,\n",
       " 'blood': 362,\n",
       " 'blossoms': 363,\n",
       " 'blows': 364,\n",
       " 'blue': 365,\n",
       " 'blunder': 366,\n",
       " 'blurb': 367,\n",
       " 'boarded': 368,\n",
       " 'boat': 369,\n",
       " 'boathouse': 370,\n",
       " 'boats': 371,\n",
       " 'bob': 372,\n",
       " 'body': 373,\n",
       " 'bolstered': 374,\n",
       " 'bolton': 375,\n",
       " 'bomb': 376,\n",
       " 'bombs': 377,\n",
       " 'bonds': 378,\n",
       " 'booing': 379,\n",
       " 'book': 380,\n",
       " 'bookie': 381,\n",
       " 'books': 382,\n",
       " 'boone': 383,\n",
       " \"boone's\": 384,\n",
       " 'boots': 385,\n",
       " 'border': 386,\n",
       " 'born': 387,\n",
       " 'borrows': 388,\n",
       " 'boss': 389,\n",
       " \"boss's\": 390,\n",
       " 'both': 391,\n",
       " 'bottle': 392,\n",
       " 'bottom': 393,\n",
       " 'bounced': 394,\n",
       " 'bound': 395,\n",
       " 'box': 396,\n",
       " 'boxes': 397,\n",
       " 'boxing': 398,\n",
       " 'boy': 399,\n",
       " 'boyfriend': 400,\n",
       " 'boyhood': 401,\n",
       " 'boys': 402,\n",
       " 'brackley': 403,\n",
       " 'brain': 404,\n",
       " 'brandishing': 405,\n",
       " 'brands': 406,\n",
       " 'brave': 407,\n",
       " 'bravery': 408,\n",
       " 'bread': 409,\n",
       " 'break': 410,\n",
       " 'breaking': 411,\n",
       " 'breaks': 412,\n",
       " 'breeding': 413,\n",
       " 'brewster': 414,\n",
       " 'brick': 415,\n",
       " 'bricks': 416,\n",
       " 'bride': 417,\n",
       " 'bridge': 418,\n",
       " 'brief': 419,\n",
       " 'bring': 420,\n",
       " 'bringing': 421,\n",
       " 'brings': 422,\n",
       " 'broken': 423,\n",
       " 'brook': 424,\n",
       " 'brother': 425,\n",
       " \"brother's\": 426,\n",
       " 'brought': 427,\n",
       " 'brown': 428,\n",
       " \"brown's\": 429,\n",
       " 'bucket': 430,\n",
       " 'building': 431,\n",
       " 'builds': 432,\n",
       " 'bull': 433,\n",
       " 'bullet': 434,\n",
       " 'bump': 435,\n",
       " 'bumps': 436,\n",
       " 'bunch': 437,\n",
       " 'bungles': 438,\n",
       " 'burgundy': 439,\n",
       " 'burly': 440,\n",
       " 'burning': 441,\n",
       " 'burns': 442,\n",
       " 'burst': 443,\n",
       " 'bursts': 444,\n",
       " 'bushel': 445,\n",
       " 'bushes': 446,\n",
       " 'business': 447,\n",
       " 'busy': 448,\n",
       " 'but': 449,\n",
       " 'butch': 450,\n",
       " 'butler': 451,\n",
       " 'buttonbright': 452,\n",
       " 'buy': 453,\n",
       " 'buys': 454,\n",
       " 'by': 455,\n",
       " 'cabin': 456,\n",
       " 'cable': 457,\n",
       " 'cafe': 458,\n",
       " 'california': 459,\n",
       " 'call': 460,\n",
       " 'called': 461,\n",
       " 'callous': 462,\n",
       " 'calls': 463,\n",
       " 'camera': 464,\n",
       " 'camp': 465,\n",
       " 'camping': 466,\n",
       " 'campout': 467,\n",
       " 'can': 468,\n",
       " \"can't\": 469,\n",
       " 'candy': 470,\n",
       " 'cane': 471,\n",
       " 'canine': 472,\n",
       " 'cannot': 473,\n",
       " 'captain': 474,\n",
       " 'capture': 475,\n",
       " 'captured': 476,\n",
       " 'captures': 477,\n",
       " 'car': 478,\n",
       " 'card': 479,\n",
       " 'cards': 480,\n",
       " 'care': 481,\n",
       " 'career': 482,\n",
       " 'careful': 483,\n",
       " 'carelessness': 484,\n",
       " 'cargo': 485,\n",
       " 'caricatures': 486,\n",
       " 'carnegie': 487,\n",
       " 'carol': 488,\n",
       " 'carpet': 489,\n",
       " 'carriage': 490,\n",
       " 'carrie': 491,\n",
       " 'carries': 492,\n",
       " 'carruthers': 493,\n",
       " 'carrying': 494,\n",
       " 'cars': 495,\n",
       " 'cart': 496,\n",
       " 'cartridge': 497,\n",
       " 'cartridges': 498,\n",
       " 'case': 499,\n",
       " 'cash': 500,\n",
       " 'castle': 501,\n",
       " 'castro': 502,\n",
       " 'cat': 503,\n",
       " 'catastrophe': 504,\n",
       " 'catch': 505,\n",
       " 'catcher': 506,\n",
       " 'catches': 507,\n",
       " 'caught': 508,\n",
       " 'cause': 509,\n",
       " 'caused': 510,\n",
       " 'causes': 511,\n",
       " 'causing': 512,\n",
       " 'cavalry': 513,\n",
       " 'ceiling': 514,\n",
       " 'celebrates': 515,\n",
       " 'celebration': 516,\n",
       " 'cell': 517,\n",
       " 'censure': 518,\n",
       " 'center': 519,\n",
       " 'centres': 520,\n",
       " 'chair': 521,\n",
       " 'challenge': 522,\n",
       " 'challenges': 523,\n",
       " 'challenging': 524,\n",
       " 'champion': 525,\n",
       " 'chance': 526,\n",
       " 'chances': 527,\n",
       " 'change': 528,\n",
       " 'changed': 529,\n",
       " 'changes': 530,\n",
       " 'chaplin': 531,\n",
       " \"chaplin's\": 532,\n",
       " 'chapter': 533,\n",
       " 'chapters': 534,\n",
       " 'character': 535,\n",
       " 'characters': 536,\n",
       " 'charge': 537,\n",
       " 'charges': 538,\n",
       " 'charity': 539,\n",
       " 'charles': 540,\n",
       " 'charlie': 541,\n",
       " \"charlie's\": 542,\n",
       " 'charming': 543,\n",
       " 'charms': 544,\n",
       " 'chase': 545,\n",
       " 'chased': 546,\n",
       " 'chases': 547,\n",
       " 'chasing': 548,\n",
       " 'chauffeur': 549,\n",
       " 'cheats': 550,\n",
       " 'check': 551,\n",
       " 'checks': 552,\n",
       " 'cheek': 553,\n",
       " 'cheerless': 554,\n",
       " 'cheshire': 555,\n",
       " 'chest': 556,\n",
       " 'chester': 557,\n",
       " 'chief': 558,\n",
       " 'child': 559,\n",
       " 'childhood': 560,\n",
       " 'children': 561,\n",
       " \"children's\": 562,\n",
       " 'chimney': 563,\n",
       " 'choices': 564,\n",
       " 'chooses': 565,\n",
       " 'chops': 566,\n",
       " 'chosen': 567,\n",
       " 'christianity': 568,\n",
       " 'christmas': 569,\n",
       " 'chronicles': 570,\n",
       " 'chum': 571,\n",
       " 'chums': 572,\n",
       " 'church': 573,\n",
       " 'cigarette': 574,\n",
       " 'cinderella': 575,\n",
       " \"cinderella's\": 576,\n",
       " 'citing': 577,\n",
       " 'city': 578,\n",
       " 'civil': 579,\n",
       " 'claim': 580,\n",
       " 'claims': 581,\n",
       " 'class': 582,\n",
       " 'classic': 583,\n",
       " 'claus': 584,\n",
       " 'clean': 585,\n",
       " 'clear': 586,\n",
       " 'clearfield': 587,\n",
       " 'cleo': 588,\n",
       " \"cleo's\": 589,\n",
       " 'clerk': 590,\n",
       " 'clever': 591,\n",
       " 'cliff': 592,\n",
       " 'clifton': 593,\n",
       " 'climax': 594,\n",
       " 'climb': 595,\n",
       " 'climbing': 596,\n",
       " 'climbs': 597,\n",
       " 'clock': 598,\n",
       " 'close': 599,\n",
       " 'closed': 600,\n",
       " 'closely': 601,\n",
       " 'closes': 602,\n",
       " 'cloth': 603,\n",
       " 'clothes': 604,\n",
       " 'club': 605,\n",
       " 'coach': 606,\n",
       " 'coat': 607,\n",
       " 'coating': 608,\n",
       " 'coats': 609,\n",
       " 'cocks': 610,\n",
       " 'cocktails': 611,\n",
       " 'codriver': 612,\n",
       " 'cohen': 613,\n",
       " 'cohen’s': 614,\n",
       " 'coin': 615,\n",
       " 'cold': 616,\n",
       " 'cole': 617,\n",
       " 'collapses': 618,\n",
       " 'collected': 619,\n",
       " 'collecting': 620,\n",
       " 'college': 621,\n",
       " 'colonists': 622,\n",
       " 'colony': 623,\n",
       " 'combat': 624,\n",
       " 'come': 625,\n",
       " 'comedic': 626,\n",
       " 'comediennes': 627,\n",
       " 'comedies': 628,\n",
       " 'comedy': 629,\n",
       " 'comes': 630,\n",
       " 'comfortable': 631,\n",
       " 'comic': 632,\n",
       " 'comical': 633,\n",
       " 'comically': 634,\n",
       " 'coming': 635,\n",
       " 'commanders': 636,\n",
       " 'commission': 637,\n",
       " 'commit': 638,\n",
       " 'committee': 639,\n",
       " 'common': 640,\n",
       " 'commonly': 641,\n",
       " 'community': 642,\n",
       " 'companion': 643,\n",
       " 'companions': 644,\n",
       " 'company': 645,\n",
       " \"company's\": 646,\n",
       " 'compels': 647,\n",
       " 'compensate': 648,\n",
       " 'complicate': 649,\n",
       " 'comply': 650,\n",
       " 'composed': 651,\n",
       " 'concealed': 652,\n",
       " 'concealing': 653,\n",
       " 'conceals': 654,\n",
       " 'concerned': 655,\n",
       " 'concerns': 656,\n",
       " 'concession': 657,\n",
       " 'concludes': 658,\n",
       " 'conclusion': 659,\n",
       " 'condemns': 660,\n",
       " 'condition': 661,\n",
       " 'confederacy': 662,\n",
       " 'confederate': 663,\n",
       " 'confesses': 664,\n",
       " 'confession': 665,\n",
       " 'confidently': 666,\n",
       " 'confirms': 667,\n",
       " 'conflict': 668,\n",
       " 'conflicts': 669,\n",
       " 'confronting': 670,\n",
       " 'confronts': 671,\n",
       " 'confusion': 672,\n",
       " 'congratulate': 673,\n",
       " 'congratulates': 674,\n",
       " 'conjunction': 675,\n",
       " 'conklin': 676,\n",
       " 'conquer': 677,\n",
       " 'conquered': 678,\n",
       " 'conquering': 679,\n",
       " 'conqueror': 680,\n",
       " 'conquerors': 681,\n",
       " 'conscience': 682,\n",
       " 'consciousness': 683,\n",
       " 'consecutive': 684,\n",
       " 'consents': 685,\n",
       " 'consider': 686,\n",
       " 'considered': 687,\n",
       " 'consisting': 688,\n",
       " 'consists': 689,\n",
       " 'consorting': 690,\n",
       " 'conspiracy': 691,\n",
       " 'conspirators': 692,\n",
       " 'conspires': 693,\n",
       " 'constantly': 694,\n",
       " 'construction': 695,\n",
       " 'contact': 696,\n",
       " 'container': 697,\n",
       " 'contemplated': 698,\n",
       " 'content': 699,\n",
       " 'continue': 700,\n",
       " 'continues': 701,\n",
       " 'contracts': 702,\n",
       " 'contrasting': 703,\n",
       " 'contribute': 704,\n",
       " 'control': 705,\n",
       " 'controls': 706,\n",
       " 'controversy': 707,\n",
       " 'conveniently': 708,\n",
       " 'convenientlyplaced': 709,\n",
       " 'conversation': 710,\n",
       " 'convert': 711,\n",
       " 'converted': 712,\n",
       " 'convey': 713,\n",
       " 'convince': 714,\n",
       " 'convulses': 715,\n",
       " 'cook': 716,\n",
       " 'copperfield': 717,\n",
       " 'cops': 718,\n",
       " 'corner': 719,\n",
       " 'correct': 720,\n",
       " 'corridor': 721,\n",
       " 'costar': 722,\n",
       " 'costume': 723,\n",
       " 'cottage': 724,\n",
       " 'couderc': 725,\n",
       " 'could': 726,\n",
       " 'counters': 727,\n",
       " 'country': 728,\n",
       " 'countryside': 729,\n",
       " 'couple': 730,\n",
       " \"couple's\": 731,\n",
       " 'couples': 732,\n",
       " 'course': 733,\n",
       " 'courted': 734,\n",
       " 'courtier': 735,\n",
       " 'courting': 736,\n",
       " 'courtyard': 737,\n",
       " 'cover': 738,\n",
       " 'covers': 739,\n",
       " 'cow': 740,\n",
       " 'cowardly': 741,\n",
       " 'coworker': 742,\n",
       " 'crack': 743,\n",
       " 'cradle': 744,\n",
       " 'crafty': 745,\n",
       " 'crampton': 746,\n",
       " 'crashing': 747,\n",
       " 'crazed': 748,\n",
       " 'creaks': 749,\n",
       " 'created': 750,\n",
       " 'creature': 751,\n",
       " 'credit': 752,\n",
       " 'crestfallen': 753,\n",
       " 'crew': 754,\n",
       " 'crime': 755,\n",
       " 'criminal': 756,\n",
       " 'criminals': 757,\n",
       " 'crippled': 758,\n",
       " 'crisis': 759,\n",
       " 'crisp': 760,\n",
       " 'critically': 761,\n",
       " 'crockery': 762,\n",
       " 'crookback': 763,\n",
       " \"crookback's\": 764,\n",
       " 'cross': 765,\n",
       " 'crosses': 766,\n",
       " 'crossing': 767,\n",
       " 'crowd': 768,\n",
       " 'crowning': 769,\n",
       " 'cruel': 770,\n",
       " 'crying': 771,\n",
       " 'culminate': 772,\n",
       " 'curious': 773,\n",
       " 'currents': 774,\n",
       " 'curtain': 775,\n",
       " 'customers': 776,\n",
       " 'cut': 777,\n",
       " 'cutaway': 778,\n",
       " 'cuts': 779,\n",
       " 'cutter': 780,\n",
       " 'cyclone': 781,\n",
       " 'daisies': 782,\n",
       " 'damsel': 783,\n",
       " 'dance': 784,\n",
       " 'dancer': 785,\n",
       " 'dancing': 786,\n",
       " 'danger': 787,\n",
       " 'dangerous': 788,\n",
       " 'dangerously': 789,\n",
       " 'daniel': 790,\n",
       " \"daniel's\": 791,\n",
       " 'darkhaired': 792,\n",
       " 'dart': 793,\n",
       " 'daughter': 794,\n",
       " \"daughter's\": 795,\n",
       " 'daughters': 796,\n",
       " 'david': 797,\n",
       " 'day': 798,\n",
       " 'days': 799,\n",
       " 'dead': 800,\n",
       " 'deal': 801,\n",
       " 'deals': 802,\n",
       " 'deanetanner': 803,\n",
       " 'death': 804,\n",
       " 'debt': 805,\n",
       " 'debts': 806,\n",
       " 'december': 807,\n",
       " 'decide': 808,\n",
       " 'decided': 809,\n",
       " 'decides': 810,\n",
       " 'deciding': 811,\n",
       " 'declare': 812,\n",
       " 'declares': 813,\n",
       " 'decorated': 814,\n",
       " 'deep': 815,\n",
       " 'deeply': 816,\n",
       " 'defeat': 817,\n",
       " 'defeated': 818,\n",
       " 'defeating': 819,\n",
       " 'defense': 820,\n",
       " 'dejected': 821,\n",
       " 'delight': 822,\n",
       " 'delighted': 823,\n",
       " 'delivered': 824,\n",
       " 'delusional': 825,\n",
       " 'demands': 826,\n",
       " 'demolished': 827,\n",
       " 'demon': 828,\n",
       " 'den': 829,\n",
       " 'denied': 830,\n",
       " 'denis': 831,\n",
       " 'denmark': 832,\n",
       " 'dental': 833,\n",
       " 'dentist': 834,\n",
       " \"dentist's\": 835,\n",
       " 'departs': 836,\n",
       " 'depose': 837,\n",
       " 'deposed': 838,\n",
       " 'depression': 839,\n",
       " 'descend': 840,\n",
       " 'describe': 841,\n",
       " 'described': 842,\n",
       " 'description': 843,\n",
       " 'desert': 844,\n",
       " 'deserts': 845,\n",
       " 'desire': 846,\n",
       " 'desk': 847,\n",
       " 'desmond': 848,\n",
       " 'despair': 849,\n",
       " 'desperado': 850,\n",
       " 'desperate': 851,\n",
       " 'desperately': 852,\n",
       " 'desperation': 853,\n",
       " 'despite': 854,\n",
       " 'despondent': 855,\n",
       " 'destitute': 856,\n",
       " 'details': 857,\n",
       " 'detective': 858,\n",
       " 'determination': 859,\n",
       " 'determined': 860,\n",
       " 'devastated': 861,\n",
       " 'develop': 862,\n",
       " 'develops': 863,\n",
       " 'devises': 864,\n",
       " 'devoted': 865,\n",
       " 'devoting': 866,\n",
       " 'diamond': 867,\n",
       " 'dick': 868,\n",
       " \"dick's\": 869,\n",
       " 'dictator': 870,\n",
       " 'did': 871,\n",
       " 'died': 872,\n",
       " 'dies': 873,\n",
       " 'different': 874,\n",
       " 'digs': 875,\n",
       " 'diligently': 876,\n",
       " 'dillon': 877,\n",
       " 'directed': 878,\n",
       " 'directly': 879,\n",
       " 'director': 880,\n",
       " 'directs': 881,\n",
       " 'disappear': 882,\n",
       " 'disappearance': 883,\n",
       " 'disappears': 884,\n",
       " 'disappointed': 885,\n",
       " 'disaster': 886,\n",
       " 'disconnect': 887,\n",
       " 'discover': 888,\n",
       " 'discovered': 889,\n",
       " 'discovering': 890,\n",
       " 'discovers': 891,\n",
       " 'disgrace': 892,\n",
       " 'disguise': 893,\n",
       " 'disguised': 894,\n",
       " 'dismisses': 895,\n",
       " 'disorder': 896,\n",
       " 'disowns': 897,\n",
       " 'dispatch': 898,\n",
       " 'dispatched': 899,\n",
       " 'displays': 900,\n",
       " 'disrupting': 901,\n",
       " 'disrupts': 902,\n",
       " 'dissappears': 903,\n",
       " 'dissolute': 904,\n",
       " 'distracted': 905,\n",
       " 'distraught': 906,\n",
       " 'distress': 907,\n",
       " 'diversionary': 908,\n",
       " 'divest': 909,\n",
       " 'divide': 910,\n",
       " 'divided': 911,\n",
       " 'divine': 912,\n",
       " 'dizzy': 913,\n",
       " 'do': 914,\n",
       " 'doctor': 915,\n",
       " \"doctor's\": 916,\n",
       " 'documented': 917,\n",
       " 'does': 918,\n",
       " \"doesn't\": 919,\n",
       " 'dog': 920,\n",
       " \"dog's\": 921,\n",
       " 'doing': 922,\n",
       " 'doll': 923,\n",
       " 'dollars': 924,\n",
       " 'dollie': 925,\n",
       " 'dolls': 926,\n",
       " 'domineering': 927,\n",
       " 'don': 928,\n",
       " 'donald': 929,\n",
       " 'donate': 930,\n",
       " 'done': 931,\n",
       " 'donor': 932,\n",
       " 'dooms': 933,\n",
       " 'door': 934,\n",
       " 'doors': 935,\n",
       " 'dorothy': 936,\n",
       " 'dorthy': 937,\n",
       " 'dose': 938,\n",
       " 'dough': 939,\n",
       " 'dousing': 940,\n",
       " 'down': 941,\n",
       " 'downandout': 942,\n",
       " 'downstream': 943,\n",
       " 'dozen': 944,\n",
       " 'dr': 945,\n",
       " 'drag': 946,\n",
       " 'dragged': 947,\n",
       " 'drags': 948,\n",
       " 'drama': 949,\n",
       " 'dramatically': 950,\n",
       " 'dramatization': 951,\n",
       " 'drastic': 952,\n",
       " 'draw': 953,\n",
       " 'drawing': 954,\n",
       " 'drawn': 955,\n",
       " 'dream': 956,\n",
       " 'dreamer': 957,\n",
       " \"dreamer's\": 958,\n",
       " 'dreams': 959,\n",
       " 'dress': 960,\n",
       " 'dressed': 961,\n",
       " 'dresses': 962,\n",
       " 'dressing': 963,\n",
       " 'dressingroom': 964,\n",
       " 'drifting': 965,\n",
       " 'drink': 966,\n",
       " 'drinking': 967,\n",
       " 'drinks': 968,\n",
       " 'drive': 969,\n",
       " 'drivers': 970,\n",
       " 'drives': 971,\n",
       " 'driving': 972,\n",
       " 'drop': 973,\n",
       " 'drops': 974,\n",
       " 'drown': 975,\n",
       " 'drowned': 976,\n",
       " 'drug': 977,\n",
       " 'drunk': 978,\n",
       " 'drunken': 979,\n",
       " \"duchess's\": 980,\n",
       " 'duckworth': 981,\n",
       " 'due': 982,\n",
       " 'duke': 983,\n",
       " 'dummy': 984,\n",
       " 'dummypunchbag': 985,\n",
       " 'dumping': 986,\n",
       " 'durfee': 987,\n",
       " 'during': 988,\n",
       " 'dutifully': 989,\n",
       " 'dweller': 990,\n",
       " 'dying': 991,\n",
       " 'dynamite': 992,\n",
       " 'each': 993,\n",
       " 'eagerly': 994,\n",
       " 'earlier': 995,\n",
       " 'earliest': 996,\n",
       " 'early': 997,\n",
       " 'ears': 998,\n",
       " 'easily': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The moon, painted with a smiling face hangs over a park at night. A young couple walking past a fence learn on a railing and look up. The moon smiles. They embrace, and the moon's smile gets bigger. They then sit down on a bench by a tree. The moon's view is blocked, causing him to frown. In the last scene, the man fans the woman with his hat because the moon has left the sky and is perched over her shoulder to see everything better.\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Plot[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsiaoyuchiang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a a a a a a he is walking past a thief falls decide to boys where the girl the\n"
     ]
    }
   ],
   "source": [
    "words_number = 10 # number of words to generate\n",
    "seed_sentences = \"he is walking past \" #seed sentence to start the generating.\n",
    "\n",
    "#initiate sentences\n",
    "generated = ''\n",
    "sentence = []\n",
    "\n",
    "#we shate the seed accordingly to the neural netwrok needs:\n",
    "for i in range (seq_length):\n",
    "    sentence.append(\"a\")\n",
    "\n",
    "seed = seed_sentences.split()\n",
    "\n",
    "for i in range(len(seed)):\n",
    "    sentence[seq_length-i-1]=seed[len(seed)-i-1]\n",
    "\n",
    "generated += ' '.join(sentence)\n",
    "\n",
    "#the, we generate the text\n",
    "for i in range(words_number):\n",
    "    #create the vector\n",
    "    x = np.zeros((1, seq_length, vocab_size))\n",
    "    for t, word in enumerate(sentence):\n",
    "        x[0, t, vocab[word]] = 1.\n",
    "\n",
    "    #calculate next word\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_index = sample(preds, 0.33)\n",
    "    next_word = vocabulary_inv[next_index]\n",
    "\n",
    "    #add the next word to the text\n",
    "    generated += \" \" + next_word\n",
    "    # shift the sentence by one, and and the next word at its end\n",
    "    sentence = sentence[1:] + [next_word]\n",
    "\n",
    "#print the whole text\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
